{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPjQglE0MphXx9lW8BM0EA9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anamarijaeres/Analysis-of-the-Relationship-between-Movie-Titles-and-Corresponding-Ratings-and-Reviews/blob/main/4_1_3_Correlation_between_the_number_of_words_in_the_title_and_ratings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two analysis are done here:\n",
        "\n",
        "*   first multiclassification with deep learning models \n",
        "  *   input: no. of words in the title\n",
        "  *   output: one out of 10 classes, each class represents rounded rating {1,2,3,4,5,6,7,8,9,10}   \n",
        "*   linear regression with keras:\n",
        "  *   input: no. of words in the title\n",
        "  *   output: one value between [0-10] \n",
        "  *   dataset is split into train_set, validation_set and finnaly for evaluation--test_set\n",
        "*   linear regression with sklearn\n",
        "  *   input: no. of words in the title\n",
        "  *   output: one value between [0-10] \n",
        "  *   dataset is split into train_set and for evaluation--test_set\n",
        "\n"
      ],
      "metadata": {
        "id": "EOK52SHeM_0_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElnC_kr0j2FX"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To read/write data from Google Drive:\n",
        "#Reference: https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveAå\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_excel('/content/drive/My Drive/datase.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz8xGHgHkYcT",
        "outputId": "cec7a005-771d-46be-9cdb-003d6b08b185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "xa2ZHqy_paEE",
        "outputId": "e13537ad-24cd-48aa-ffee-776c02d124b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6c6d36ac-0455-4898-af92-53e3b08a364e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>\"mov_galaxy_ID\"</th>\n",
              "      <th>\"imdbID\"</th>\n",
              "      <th>\"title\"</th>\n",
              "      <th>\"rating\"</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"001\"</td>\n",
              "      <td>\"0147800\"</td>\n",
              "      <td>\"10 Things I Hate About You\"</td>\n",
              "      <td>\"7.2\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"003\"</td>\n",
              "      <td>\"0417385\"</td>\n",
              "      <td>\"12 and Holding\"</td>\n",
              "      <td>\"7.6\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"005\"</td>\n",
              "      <td>\"1542344\"</td>\n",
              "      <td>\"127 Hours\"</td>\n",
              "      <td>\"7.6\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"006\"</td>\n",
              "      <td>\"0103594\"</td>\n",
              "      <td>\"1492: Conquest of Paradise\"</td>\n",
              "      <td>\"6.5\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"007\"</td>\n",
              "      <td>\"0179626\"</td>\n",
              "      <td>\"15 Minutes\"</td>\n",
              "      <td>\"6.1\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750</th>\n",
              "      <td>\"908\"</td>\n",
              "      <td>\"0295701\"</td>\n",
              "      <td>\"xXx\"</td>\n",
              "      <td>\"5.8\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>\"910\"</td>\n",
              "      <td>\"1068680\"</td>\n",
              "      <td>\"Yes Man\"</td>\n",
              "      <td>\"6.8\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>752</th>\n",
              "      <td>\"911\"</td>\n",
              "      <td>\"0203230\"</td>\n",
              "      <td>\"You Can Count on Me\"</td>\n",
              "      <td>\"7.7\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753</th>\n",
              "      <td>\"913\"</td>\n",
              "      <td>\"0403702\"</td>\n",
              "      <td>\"Youth in Revolt\"</td>\n",
              "      <td>\"6.5\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>754</th>\n",
              "      <td>\"914\"</td>\n",
              "      <td>\"0421090\"</td>\n",
              "      <td>\"Zerophilia\"</td>\n",
              "      <td>\"6.3\"</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>755 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c6d36ac-0455-4898-af92-53e3b08a364e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c6d36ac-0455-4898-af92-53e3b08a364e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c6d36ac-0455-4898-af92-53e3b08a364e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    \"mov_galaxy_ID\"   \"imdbID\"                       \"title\" \"rating\"\n",
              "0             \"001\"  \"0147800\"  \"10 Things I Hate About You\"    \"7.2\"\n",
              "1             \"003\"  \"0417385\"              \"12 and Holding\"    \"7.6\"\n",
              "2             \"005\"  \"1542344\"                   \"127 Hours\"    \"7.6\"\n",
              "3             \"006\"  \"0103594\"  \"1492: Conquest of Paradise\"    \"6.5\"\n",
              "4             \"007\"  \"0179626\"                  \"15 Minutes\"    \"6.1\"\n",
              "..              ...        ...                           ...      ...\n",
              "750           \"908\"  \"0295701\"                         \"xXx\"    \"5.8\"\n",
              "751           \"910\"  \"1068680\"                     \"Yes Man\"    \"6.8\"\n",
              "752           \"911\"  \"0203230\"         \"You Can Count on Me\"    \"7.7\"\n",
              "753           \"913\"  \"0403702\"             \"Youth in Revolt\"    \"6.5\"\n",
              "754           \"914\"  \"0421090\"                  \"Zerophilia\"    \"6.3\"\n",
              "\n",
              "[755 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n",
        "df=df.drop(['\"imdbID\"'], axis=1) \n",
        "df=df.drop(['\"mov_galaxy_ID\"'], axis=1) \n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SCMuX2rHqZBf",
        "outputId": "22601ebe-d50f-4487-e59e-4729b7be302a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7b3f9e53-51df-48dc-aef7-584b7c04c99d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>\"title\"</th>\n",
              "      <th>\"rating\"</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"10 Things I Hate About You\"</td>\n",
              "      <td>\"7.2\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"12 and Holding\"</td>\n",
              "      <td>\"7.6\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"127 Hours\"</td>\n",
              "      <td>\"7.6\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"1492: Conquest of Paradise\"</td>\n",
              "      <td>\"6.5\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"15 Minutes\"</td>\n",
              "      <td>\"6.1\"</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b3f9e53-51df-48dc-aef7-584b7c04c99d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b3f9e53-51df-48dc-aef7-584b7c04c99d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b3f9e53-51df-48dc-aef7-584b7c04c99d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                        \"title\" \"rating\"\n",
              "0  \"10 Things I Hate About You\"    \"7.2\"\n",
              "1              \"12 and Holding\"    \"7.6\"\n",
              "2                   \"127 Hours\"    \"7.6\"\n",
              "3  \"1492: Conquest of Paradise\"    \"6.5\"\n",
              "4                  \"15 Minutes\"    \"6.1\""
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tensor=tf.convert_to_tensor(df)\n",
        "df_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtOaImtdsTOt",
        "outputId": "7a670072-cae4-4380-e905-94e20b3b0f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(755, 2), dtype=string, numpy=\n",
              "array([[b'\"10 Things I Hate About You\"', b'\"7.2\"'],\n",
              "       [b'\"12 and Holding\"', b'\"7.6\"'],\n",
              "       [b'\"127 Hours\"', b'\"7.6\"'],\n",
              "       ...,\n",
              "       [b'\"You Can Count on Me\"', b'\"7.7\"'],\n",
              "       [b'\"Youth in Revolt\"', b'\"6.5\"'],\n",
              "       [b'\"Zerophilia\"', b'\"6.3\"']], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This is model for classification problem -- not really sure when I will need it \n",
        "def get_basic_model():\n",
        "  model = tf.keras.Sequential([\n",
        "    #tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "srrgiJqjw06E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_names= df['\"title\"'].tolist()\n",
        "list_names[:3]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J800ZVhH1HWE",
        "outputId": "ab205992-b546-45cd-fc11-6ef34b3ad684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"10 Things I Hate About You\"', '\"12 and Holding\"', '\"127 Hours\"']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "list_noOfWords=[]\n",
        "for i in list_names:\n",
        "  cnt=0\n",
        "  for j in i:\n",
        "    if j==\" \":\n",
        "      cnt+=1\n",
        "  cnt+=1\n",
        "  list_noOfWords.append([cnt])\n",
        "print(list_names[:3])\n",
        "print(list_noOfWords[:3])\n",
        "list_noOfWords[:3]\n",
        "#preparing input dataset\n",
        "list_noOfWords_numpy=np.array(list_noOfWords) \n",
        "#list_noOfWords_numpy[:103]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBVZvfVX1080",
        "outputId": "a7e9cedf-62b9-4c59-9019-eb6b9c8c58c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\"10 Things I Hate About You\"', '\"12 and Holding\"', '\"127 Hours\"']\n",
            "[[6], [3], [2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from tensorflow.python.eager.context import num_gpus\n",
        "list_ratings= df['\"rating\"'].tolist()\n",
        "#list_ratings[:3]\n",
        "list_int_ratings=[]\n",
        "list_float_ratings_linear=[]\n",
        "for i in list_ratings:\n",
        "  num=''\n",
        "  for j in i:\n",
        "    if j!= \"\\\"\":\n",
        "      #print(j)\n",
        "      num+=j\n",
        " # print(num)\n",
        "  if num==\"?\": # fill missing values with rating 5 \n",
        "    num='5'\n",
        "  rating=int(round(float(num)))\n",
        "  rating_linear=float(num)\n",
        "  #print(rating)\n",
        "  list_int_ratings.append([rating])\n",
        "  list_float_ratings_linear.append([rating_linear])\n",
        "\n",
        "list_int_ratings_numpy= np.array(list_int_ratings)\n",
        "list_float_ratings_numpy_linear= np.array(list_float_ratings_linear)\n",
        "list_int_ratings_numpy[:3]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoQizX677dS4",
        "outputId": "e6cef85f-731a-4464-c1f0-fe4d342e7c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7],\n",
              "       [8],\n",
              "       [8]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_val = tf.convert_to_tensor(np.array(list_noOfWords_numpy[:100]))\n",
        "x_test=tf.convert_to_tensor(np.array(list_noOfWords_numpy[100:200]))\n",
        "partial_x_train = tf.convert_to_tensor(np.array(list_noOfWords_numpy[200:]))\n",
        "\n",
        "#this values are used for multiclassification\n",
        "y_val = tf.convert_to_tensor(np.array(list_int_ratings_numpy[:100]))\n",
        "y_test_numpy=np.array(list_int_ratings_numpy[100:200])\n",
        "y_test= tf.convert_to_tensor(y_test_numpy)\n",
        "partial_y_train = tf.convert_to_tensor(np.array(list_int_ratings_numpy[200:]))\n",
        "\n",
        "#this values are used for linear regression\n",
        "y_val_linear = tf.convert_to_tensor(np.array(list_float_ratings_numpy_linear[:100]))\n",
        "y_test_linear= tf.convert_to_tensor(np.array(list_float_ratings_numpy_linear[100:200]))\n",
        "partial_y_train_linear = tf.convert_to_tensor(np.array(list_float_ratings_numpy_linear[200:]))\n"
      ],
      "metadata": {
        "id": "TA-mpSCa-6Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#i'm not using this for now\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(partial_x_train)\n",
        "normalizer(partial_x_train[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK_pF8irD4FG",
        "outputId": "2a3d7090-6000-46c4-d6c6-927c9a77fcee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
              "array([[1.4529574 ],\n",
              "       [2.0756533 ],\n",
              "       [0.20756516]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "#model.add(normalizer)\n",
        "#model.add(tf.keras.layers.Dense(1, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
        "model.add(Dense(10,activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), # default from_logits=False\n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "    \n",
        "              # optimizer='adam',\n",
        "              #loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "              #loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
        "              #metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])\n",
        "              #loss='mean_squared_error')\n",
        "              #metrics=['mean_squared_error'])\n",
        "\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=200,\n",
        "                    batch_size=256,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBYH8BsYAqE5",
        "outputId": "907f1a6c-7b83-4778-86f1-7b491af51325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 79ms/step - loss: 2.9414 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 2.9275 - val_sparse_categorical_accuracy: 0.0100\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.8883 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 2.8730 - val_sparse_categorical_accuracy: 0.0100\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.8359 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 2.8196 - val_sparse_categorical_accuracy: 0.0100\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.7858 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 2.7676 - val_sparse_categorical_accuracy: 0.0100\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.7360 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 2.7172 - val_sparse_categorical_accuracy: 0.0100\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.6887 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 2.6681 - val_sparse_categorical_accuracy: 0.0100\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.6423 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 2.6206 - val_sparse_categorical_accuracy: 0.0100\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.5977 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 2.5743 - val_sparse_categorical_accuracy: 0.0100\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.5547 - sparse_categorical_accuracy: 0.0505 - val_loss: 2.5296 - val_sparse_categorical_accuracy: 0.0800\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.5121 - sparse_categorical_accuracy: 0.0973 - val_loss: 2.4865 - val_sparse_categorical_accuracy: 0.0800\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 2.4721 - sparse_categorical_accuracy: 0.1838 - val_loss: 2.4444 - val_sparse_categorical_accuracy: 0.2400\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.4335 - sparse_categorical_accuracy: 0.3027 - val_loss: 2.4039 - val_sparse_categorical_accuracy: 0.2500\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.3954 - sparse_categorical_accuracy: 0.3676 - val_loss: 2.3655 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.3598 - sparse_categorical_accuracy: 0.3730 - val_loss: 2.3281 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.3250 - sparse_categorical_accuracy: 0.3730 - val_loss: 2.2917 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.2915 - sparse_categorical_accuracy: 0.3730 - val_loss: 2.2555 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.2578 - sparse_categorical_accuracy: 0.3730 - val_loss: 2.2174 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.2220 - sparse_categorical_accuracy: 0.3730 - val_loss: 2.1774 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.1846 - sparse_categorical_accuracy: 0.3730 - val_loss: 2.1382 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.1496 - sparse_categorical_accuracy: 0.3730 - val_loss: 2.1002 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.1158 - sparse_categorical_accuracy: 0.3730 - val_loss: 2.0638 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.0835 - sparse_categorical_accuracy: 0.3730 - val_loss: 2.0294 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.0533 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.9973 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.0251 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.9672 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.9980 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.9386 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.9738 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.9115 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.9504 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.8865 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.9283 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.8630 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.9081 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.8405 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.8893 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.8194 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.8714 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.7994 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.8543 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.7807 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.8384 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.7629 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.8230 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.7460 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 1.8089 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.7295 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.7948 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.7141 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.7820 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.6994 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.7694 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.6854 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.7581 - sparse_categorical_accuracy: 0.3694 - val_loss: 1.6719 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.7466 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.6591 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.7363 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.6470 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.7264 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.6363 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.7169 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.6260 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.7081 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.6163 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.6996 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.6076 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.6919 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.5992 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.6842 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.5915 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.6768 - sparse_categorical_accuracy: 0.3279 - val_loss: 1.5849 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.6701 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.5781 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.6635 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.5713 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.6572 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.5652 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.6510 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.5586 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.6449 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.5519 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.6390 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.5457 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.6334 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.5400 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.6282 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.5337 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.6228 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.5272 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.6176 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.5217 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.6126 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.5166 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.6078 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.5119 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.6033 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.5072 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.5990 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.5027 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 1.5947 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4981 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.5907 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4935 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.5868 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4895 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.5833 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4855 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.5798 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4815 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.5766 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4777 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.5734 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4746 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.5702 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4720 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.5672 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4700 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.5643 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4679 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.5614 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4654 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.5586 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4631 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.5559 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4610 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.5531 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4586 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.5506 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4566 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.5481 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4550 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.5459 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4532 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.5433 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4513 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.5410 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4495 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.5389 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4475 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.5369 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4457 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.5348 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4446 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.5329 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4443 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.5311 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4436 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.5292 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4426 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.5274 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4413 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.5256 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4396 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.5239 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4377 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.5224 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4360 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.5208 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4345 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.5193 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4334 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.5180 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4326 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.5166 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4322 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.5151 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4310 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.5135 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4290 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 1.5120 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4271 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.5110 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4260 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.5097 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4250 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.5084 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4242 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.5075 - sparse_categorical_accuracy: 0.3441 - val_loss: 1.4236 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.5063 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4228 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.5053 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4222 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.5042 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4221 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.5031 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4225 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 1.5018 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4222 - val_sparse_categorical_accuracy: 0.3400\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.5008 - sparse_categorical_accuracy: 0.3027 - val_loss: 1.4223 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.4998 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4237 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.4989 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4248 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 1.4977 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4250 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.4968 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4246 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.4959 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4237 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.4950 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4234 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.4942 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4236 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.4935 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4240 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4924 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4237 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4917 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4231 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4908 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4236 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.4899 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4234 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.4892 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4225 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.4883 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4222 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4875 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4230 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4867 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4239 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.4860 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4245 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.4852 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4236 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.4845 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4224 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4837 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4219 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4831 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4206 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.4824 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4199 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4816 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4192 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.4810 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4182 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4803 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4178 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4797 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4182 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.4789 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4191 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 1.4782 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4187 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4775 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4177 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4770 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4165 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.4762 - sparse_categorical_accuracy: 0.3369 - val_loss: 1.4159 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4754 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4143 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4748 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4126 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.4742 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4111 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.4735 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4107 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4728 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4109 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.4721 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4112 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.4715 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4111 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4709 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4120 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4701 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4129 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.4696 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4140 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.4690 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4145 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4683 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4143 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.4679 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4144 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.4672 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4151 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.4666 - sparse_categorical_accuracy: 0.3423 - val_loss: 1.4161 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4662 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4166 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4658 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4170 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.4653 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4164 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4648 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4153 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.4641 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4136 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.4636 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4112 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.4631 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4093 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4625 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4081 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4619 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4061 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4616 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4044 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.4611 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4035 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.4607 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4026 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.4602 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4022 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 1.4597 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4016 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.4592 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4015 - val_sparse_categorical_accuracy: 0.3100\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 1.4586 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.4021 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.4581 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4033 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.4574 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4046 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4568 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4067 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.4563 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4093 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.4560 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4113 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4554 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4118 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4548 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4105 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 1.4544 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4089 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4540 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4076 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.4536 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4068 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.4532 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4060 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.4528 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4063 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.4523 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4066 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.4519 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4069 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.4512 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4069 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.4508 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4069 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.4505 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4068 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4500 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4059 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.4496 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4044 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4493 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4027 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4490 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4017 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.4486 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4008 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.4481 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.4000 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.4477 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.3994 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.4474 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.3996 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.4469 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.3999 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4466 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.3992 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4462 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.3988 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.4458 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.3992 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4455 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.3996 - val_sparse_categorical_accuracy: 0.3000\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 8)                 16        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                90        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 178\n",
            "Trainable params: 178\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two values will be returned. Loss (a number which represents our error, lower values are better), and accuracy."
      ],
      "metadata": {
        "id": "2Beu9UUTKE3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(x_test, y_test)\n",
        "\n",
        "print(results)\n",
        "#poor results due to lack of examples in train set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zajvZD6SkDt",
        "outputId": "a9bbd0d1-d720-4390-dc0d-d1a35db4ca00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 1.3768 - sparse_categorical_accuracy: 0.3500\n",
            "[1.376792550086975, 0.3499999940395355]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res=model.predict(x_test)\n",
        "print(res[:10])\n",
        "print(y_test[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uywm8UR6TU7D",
        "outputId": "a6a122ed-54ee-45f2-e14e-c37e334226fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.01412556 0.00187853 0.0178422  0.01673561 0.14743623 0.721802\n",
            "  0.87234044 0.9243419  0.90184474 0.6063461 ]\n",
            " [0.01412556 0.00187853 0.0178422  0.01673561 0.14743623 0.721802\n",
            "  0.87234044 0.9243419  0.90184474 0.6063461 ]\n",
            " [0.04006752 0.01046443 0.04475909 0.04518202 0.2187823  0.6568481\n",
            "  0.80644923 0.8854077  0.8544616  0.50528604]\n",
            " [0.04006752 0.01046443 0.04475909 0.04518202 0.2187823  0.6568481\n",
            "  0.80644923 0.8854077  0.8544616  0.50528604]\n",
            " [0.01412556 0.00187853 0.0178422  0.01673561 0.14743623 0.721802\n",
            "  0.87234044 0.9243419  0.90184474 0.6063461 ]\n",
            " [0.04006752 0.01046443 0.04475909 0.04518202 0.2187823  0.6568481\n",
            "  0.80644923 0.8854077  0.8544616  0.50528604]\n",
            " [0.01412556 0.00187853 0.0178422  0.01673561 0.14743623 0.721802\n",
            "  0.87234044 0.9243419  0.90184474 0.6063461 ]\n",
            " [0.10841379 0.05608848 0.10782531 0.11626297 0.3120181  0.5854389\n",
            "  0.71755964 0.83011997 0.7895427  0.4037922 ]\n",
            " [0.04006752 0.01046443 0.04475909 0.04518202 0.2187823  0.6568481\n",
            "  0.80644923 0.8854077  0.8544616  0.50528604]\n",
            " [0.04006752 0.01046443 0.04475909 0.04518202 0.2187823  0.6568481\n",
            "  0.80644923 0.8854077  0.8544616  0.50528604]]\n",
            "tf.Tensor(\n",
            "[[8]\n",
            " [6]\n",
            " [8]\n",
            " [6]\n",
            " [6]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [8]], shape=(10, 1), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#print(max(res[0]))\n",
        "res2=[]\n",
        "for ind,r in enumerate(res):\n",
        "  print(\"Predicted:\" +str(np.argmax(r))+ \"   true value:\"+str(y_test_numpy[ind]))\n",
        "  res2.append(np.argmax(r))\n",
        "plt.scatter(x_test,y_test)\n",
        "plt.scatter(x_test,res2, color='red')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WytQphFpXJn0",
        "outputId": "34f13bdf-cd5f-4503-b03f-98f465cc1368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[5]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[5]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[5]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[5]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[4]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[7]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[8]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[6]\n",
            "Predicted:7   true value:[7]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7ff70c9ac390>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression using tf.keras.experimental.LinearModel-- difference between this one and sklearn is that test set is divided in half for test and validation-- this is why results are a bit different\n"
      ],
      "metadata": {
        "id": "j7_Hex0rMQD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = tf.keras.experimental.LinearModel()\n",
        "model.compile(optimizer='sgd', loss='mse')\n",
        "model.fit(partial_x_train, partial_y_train_linear, epochs=200,batch_size=256,\n",
        "                    validation_data=(x_val, y_val_linear),\n",
        "                    verbose=1)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P20LwCN4UN9W",
        "outputId": "57477b02-6bb7-4630-ba89-d8c4ec9d986e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 41.4590 - val_loss: 21.3224\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 18.9255 - val_loss: 14.4880\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 13.3881 - val_loss: 12.6308\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 11.8082 - val_loss: 11.8217\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 11.0998 - val_loss: 11.4124\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 10.7205 - val_loss: 11.0879\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 10.4100 - val_loss: 10.7569\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 10.1049 - val_loss: 10.4678\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 9.8288 - val_loss: 10.1706\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 9.5553 - val_loss: 9.8921\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 9.2974 - val_loss: 9.6312\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.0519 - val_loss: 9.4192\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 8.8549 - val_loss: 9.2198\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 8.6377 - val_loss: 8.9308\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.3836 - val_loss: 8.7038\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 8.1760 - val_loss: 8.4878\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 7.9719 - val_loss: 8.2477\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 7.7533 - val_loss: 8.0737\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 7.5713 - val_loss: 7.8234\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 7.3552 - val_loss: 7.6713\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.1950 - val_loss: 7.4757\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.0127 - val_loss: 7.2592\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.8345 - val_loss: 7.0864\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 6.6591 - val_loss: 6.9035\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.4978 - val_loss: 6.7431\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 6.3345 - val_loss: 6.5707\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 6.1791 - val_loss: 6.4227\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 6.0425 - val_loss: 6.2341\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 5.8777 - val_loss: 6.1003\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 5.7313 - val_loss: 5.9597\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 5.5962 - val_loss: 5.7975\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.4565 - val_loss: 5.6658\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.3268 - val_loss: 5.5425\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.2106 - val_loss: 5.4333\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 5.1037 - val_loss: 5.3223\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.9859 - val_loss: 5.1315\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.8296 - val_loss: 5.0109\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.7203 - val_loss: 4.8982\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.6161 - val_loss: 4.7876\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.5191 - val_loss: 4.6603\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.3922 - val_loss: 4.5543\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.2976 - val_loss: 4.4572\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.2058 - val_loss: 4.3289\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.0807 - val_loss: 4.2318\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.9917 - val_loss: 4.1405\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.9025 - val_loss: 4.0448\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.8172 - val_loss: 3.9556\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.7328 - val_loss: 3.8695\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.6508 - val_loss: 3.7905\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.5764 - val_loss: 3.7164\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.5205 - val_loss: 3.6257\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.4231 - val_loss: 3.5547\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.3638 - val_loss: 3.4909\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.3031 - val_loss: 3.4008\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.2155 - val_loss: 3.3241\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.1410 - val_loss: 3.2660\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 3.0856 - val_loss: 3.1876\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.0144 - val_loss: 3.1338\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.9615 - val_loss: 3.0720\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.9006 - val_loss: 3.0020\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.8445 - val_loss: 2.9481\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.7886 - val_loss: 2.8980\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.7383 - val_loss: 2.8295\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.6769 - val_loss: 2.7782\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.6270 - val_loss: 2.7165\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.5748 - val_loss: 2.6703\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.5298 - val_loss: 2.6273\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.4874 - val_loss: 2.5740\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.4412 - val_loss: 2.5353\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.4023 - val_loss: 2.4825\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.3577 - val_loss: 2.4501\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.3228 - val_loss: 2.4062\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.2825 - val_loss: 2.3722\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.2487 - val_loss: 2.3334\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.2156 - val_loss: 2.3086\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.1841 - val_loss: 2.2634\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.1458 - val_loss: 2.2150\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.1030 - val_loss: 2.1763\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.0688 - val_loss: 2.1392\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.0379 - val_loss: 2.1082\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0128 - val_loss: 2.0711\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.9800 - val_loss: 2.0334\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.9385 - val_loss: 2.0119\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.9128 - val_loss: 1.9767\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.8860 - val_loss: 1.9594\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.8645 - val_loss: 1.9352\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.8400 - val_loss: 1.8922\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.8145 - val_loss: 1.8684\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.7845 - val_loss: 1.8418\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.7625 - val_loss: 1.8185\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.7402 - val_loss: 1.7936\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.7194 - val_loss: 1.7709\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.6929 - val_loss: 1.7493\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.6720 - val_loss: 1.7268\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.6509 - val_loss: 1.6992\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.6323 - val_loss: 1.6784\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.6108 - val_loss: 1.6577\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.5933 - val_loss: 1.6378\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.5710 - val_loss: 1.6234\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.5551 - val_loss: 1.5995\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.5364 - val_loss: 1.5847\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.5205 - val_loss: 1.5699\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.5065 - val_loss: 1.5479\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.4906 - val_loss: 1.5301\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.4712 - val_loss: 1.5134\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.4578 - val_loss: 1.4999\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.4451 - val_loss: 1.4813\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4278 - val_loss: 1.4670\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.4139 - val_loss: 1.4521\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.4014 - val_loss: 1.4421\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.3885 - val_loss: 1.4261\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.3761 - val_loss: 1.4155\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.3644 - val_loss: 1.4031\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.3571 - val_loss: 1.3875\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.3437 - val_loss: 1.3757\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 1.3329 - val_loss: 1.3629\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.3198 - val_loss: 1.3529\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 1.3089 - val_loss: 1.3416\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.2999 - val_loss: 1.3306\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.2912 - val_loss: 1.3193\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.2784 - val_loss: 1.3072\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.2701 - val_loss: 1.2972\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.2603 - val_loss: 1.2885\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.2505 - val_loss: 1.2798\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.2421 - val_loss: 1.2713\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.2339 - val_loss: 1.2626\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.2267 - val_loss: 1.2554\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 1.2183 - val_loss: 1.2486\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.2140 - val_loss: 1.2460\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.2071 - val_loss: 1.2335\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 1.1971 - val_loss: 1.2255\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.1901 - val_loss: 1.2196\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.1854 - val_loss: 1.2089\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.1784 - val_loss: 1.2045\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.1706 - val_loss: 1.2030\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.1681 - val_loss: 1.1970\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.1630 - val_loss: 1.1969\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.1586 - val_loss: 1.1802\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.1491 - val_loss: 1.1859\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.1490 - val_loss: 1.1742\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 1.1399 - val_loss: 1.1628\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.1327 - val_loss: 1.1591\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.1281 - val_loss: 1.1538\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.1241 - val_loss: 1.1483\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.1187 - val_loss: 1.1419\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.1142 - val_loss: 1.1364\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.1100 - val_loss: 1.1294\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.1051 - val_loss: 1.1254\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.1012 - val_loss: 1.1209\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.0981 - val_loss: 1.1168\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0957 - val_loss: 1.1183\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0987 - val_loss: 1.1095\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.0898 - val_loss: 1.1061\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.0851 - val_loss: 1.1053\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0805 - val_loss: 1.1006\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.0772 - val_loss: 1.0971\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.0739 - val_loss: 1.0947\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.0708 - val_loss: 1.0893\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.0671 - val_loss: 1.0897\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.0653 - val_loss: 1.0855\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0619 - val_loss: 1.0810\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.0611 - val_loss: 1.0747\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.0549 - val_loss: 1.0733\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.0527 - val_loss: 1.0692\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0506 - val_loss: 1.0670\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.0476 - val_loss: 1.0643\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.0461 - val_loss: 1.0628\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.0452 - val_loss: 1.0603\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.0432 - val_loss: 1.0581\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.0420 - val_loss: 1.0572\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.0377 - val_loss: 1.0544\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.0357 - val_loss: 1.0552\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 1.0344 - val_loss: 1.0500\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.0322 - val_loss: 1.0498\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.0302 - val_loss: 1.0463\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.0277 - val_loss: 1.0442\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0264 - val_loss: 1.0402\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.0258 - val_loss: 1.0376\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.0227 - val_loss: 1.0365\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0203 - val_loss: 1.0363\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.0192 - val_loss: 1.0330\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.0202 - val_loss: 1.0296\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.0158 - val_loss: 1.0281\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0138 - val_loss: 1.0272\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0119 - val_loss: 1.0239\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0108 - val_loss: 1.0230\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.0103 - val_loss: 1.0206\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.0073 - val_loss: 1.0197\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.0062 - val_loss: 1.0175\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.0050 - val_loss: 1.0161\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0034 - val_loss: 1.0146\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.0023 - val_loss: 1.0137\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.0030 - val_loss: 1.0115\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.9998 - val_loss: 1.0122\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.9984 - val_loss: 1.0092\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.9986 - val_loss: 1.0120\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.9975 - val_loss: 1.0065\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.9958 - val_loss: 1.0101\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.9954 - val_loss: 1.0056\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.9935 - val_loss: 1.0033\n",
            "Model: \"linear_model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               multiple                  1         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(x_test, y_test)\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5lKYHavie17",
        "outputId": "192ab890-62f0-4680-90e2-de1b892aa7b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9005\n",
            "0.9005107879638672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res=model.predict(x_test)\n",
        "print(res[:10])\n",
        "print(y_test[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PADPCkiSioRY",
        "outputId": "08df798e-fed0-4b8a-9394-bef9876af15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6.955274 ]\n",
            " [6.955274 ]\n",
            " [6.8790526]\n",
            " [6.8790526]\n",
            " [6.955274 ]\n",
            " [6.8790526]\n",
            " [6.955274 ]\n",
            " [6.8028316]\n",
            " [6.8790526]\n",
            " [6.8790526]]\n",
            "tf.Tensor(\n",
            "[[8]\n",
            " [6]\n",
            " [8]\n",
            " [6]\n",
            " [6]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [8]], shape=(10, 1), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x_test,y_test_linear)\n",
        "plt.plot(x_test,res, color='red')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "xsF9SZbtiu9R",
        "outputId": "44d6fc43-2454-4ff9-a21d-129ca5209f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff708ce0a90>]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using LinearRegression from sklearn**\n",
        "\n",
        "Ordinary least squares Linear Regression.\n",
        "\n",
        "LinearRegression fits a linear model with coefficients w = (w1, …, wp) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation."
      ],
      "metadata": {
        "id": "_hFSuHJrFtcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#preparing train set\n",
        "x_val_regression = np.array(list_noOfWords_numpy[:200])\n",
        "partial_x_train_regression = np.array(list_noOfWords_numpy[200:])\n",
        "\n",
        "\n",
        "y_val_linear_regression = np.array(list_float_ratings_numpy_linear[:200])\n",
        "partial_y_train_linear_regression = np.array(list_float_ratings_numpy_linear[200:])"
      ],
      "metadata": {
        "id": "wwm6QO-SCefg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear regression\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "reg = LinearRegression().fit(partial_x_train_regression,partial_y_train_linear_regression)\n",
        "\n",
        "test=x_val_regression[0].reshape(1,-1)\n",
        "y_pred=reg.predict(x_val_regression)\n",
        "\n",
        "#print(y_pred)\n",
        "#print(y_val_linear_regression[0])\n",
        "# Plot outputs\n",
        "plt.scatter(x_val_regression, y_val_linear_regression, color=\"black\")\n",
        "plt.plot(x_val_regression, y_pred, color=\"blue\", linewidth=3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "5LXh2IyNB6US",
        "outputId": "1576217c-5b79-40b8-c9b1-29a1f4218ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff708bfd050>]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
